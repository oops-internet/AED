{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oops-internet/AED/blob/main/APP_Transcripci%C3%B3n_WX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LAsX0Tihv9Zy"
      },
      "outputs": [],
      "source": [
        "# @title Instalar Whisper X {\"vertical-output\":true}\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def install_packages(commands):\n",
        "    for command in tqdm(commands, desc=\"Instalando paquetes\", unit=\"comando\"):\n",
        "        os.system(f\"{command} > /dev/null 2>&1\")\n",
        "        time.sleep(1)\n",
        "\n",
        "def setup_cuda_library_path():\n",
        "    os.system(\"echo /usr/lib64-nvidia/ > /etc/ld.so.conf.d/libcuda.conf\")\n",
        "    os.system(\"ldconfig\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Configurando el entorno CUDA...\")\n",
        "    setup_cuda_library_path()\n",
        "    print(\"Entorno CUDA configurado correctamente.\")\n",
        "\n",
        "    commands = [\n",
        "        \"pip install git+https://github.com/openai/whisper.git -q\",\n",
        "        \"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\"\n",
        "    ]\n",
        "    install_packages(commands)\n",
        "\n",
        "    try:\n",
        "        import whisper\n",
        "        print(\"\\nWhisper instalado correctamente y listo para usarse.\")\n",
        "    except ImportError as e:\n",
        "        print(f\"\\nError durante la instalación de Whisper: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aDv6i_iDw8rf"
      },
      "outputs": [],
      "source": [
        "# @title Transcribir {\"vertical-output\":true}\n",
        "import os\n",
        "import whisper\n",
        "from tqdm import tqdm\n",
        "import contextlib\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def suppress_stdout_stderr():\n",
        "    \"\"\"Context manager to suppress stdout and stderr.\"\"\"\n",
        "    with open(os.devnull, 'w') as fnull:\n",
        "        with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n",
        "            yield\n",
        "\n",
        "LANGUAGE_MAP = {\n",
        "    \"es\": \"Español\",\n",
        "    \"en\": \"Inglés\",\n",
        "    \"fr\": \"Francés\",\n",
        "    \"de\": \"Alemán\",\n",
        "    \"it\": \"Italiano\",\n",
        "    \"pt\": \"Portugués\",\n",
        "    \"zh\": \"Chino\",\n",
        "    \"ja\": \"Japonés\",\n",
        "    \"ru\": \"Ruso\"\n",
        "}\n",
        "\n",
        "def setup_environment():\n",
        "    print(\"Configurando el entorno de ejecución...\")\n",
        "    os.system(\"pip install git+git+https://github.com/openai/whisper.git -q > /dev/null 2>&1\")\n",
        "    os.system(\"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q > /dev/null 2>&1\")\n",
        "    import torch\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"La GPU no está disponible o los controladores de CUDA no son compatibles. Verifica la configuración del entorno.\")\n",
        "    print(\"Entorno configurado correctamente. GPU disponible.\")\n",
        "\n",
        "def load_whisper_model_with_progress(model_name=\"large\", device=\"cuda\"):\n",
        "    print(\"Inicializando carga del modelo...\")\n",
        "    with tqdm(total=100, desc=\"Cargando modelo de Whisper\", unit=\"%\", unit_scale=True, dynamic_ncols=True) as progress_bar:\n",
        "        for i in range(1, 101, 10):\n",
        "            time.sleep(0.1)\n",
        "            progress_bar.update(10)\n",
        "\n",
        "    with suppress_stdout_stderr():\n",
        "        model = whisper.load_model(model_name, device=device)\n",
        "\n",
        "    print(\"Modelo cargado correctamente.\")\n",
        "    return model\n",
        "\n",
        "def upload_audio_file():\n",
        "    print(\"Por favor, sube un archivo de audio:\")\n",
        "    uploaded_files = files.upload()\n",
        "    if not uploaded_files:\n",
        "        raise FileNotFoundError(\"No se subió ningún archivo.\")\n",
        "    file_path = list(uploaded_files.keys())[0]\n",
        "    base_name, _ = os.path.splitext(file_path)\n",
        "    output_folder = f\"{base_name}_output\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    os.rename(file_path, os.path.join(output_folder, file_path))\n",
        "    print(f\"Archivo '{file_path}' cargado exitosamente y guardado en la carpeta '{output_folder}'.\")\n",
        "    return os.path.join(output_folder, file_path), output_folder, base_name\n",
        "\n",
        "def transcribe_audio_with_progress(model, audio_file, output_folder, base_name, language=\"es\"):\n",
        "    language_name = LANGUAGE_MAP.get(language, language)\n",
        "    print(f\"Transcribiendo en idioma: {language_name}...\")\n",
        "\n",
        "    transcription = None\n",
        "    with suppress_stdout_stderr():\n",
        "        with tqdm(total=100, desc=\"Progreso de transcripción\", unit=\"%\", unit_scale=True, dynamic_ncols=True) as progress_bar:\n",
        "            transcription = model.transcribe(audio_file, language=language, verbose=False)\n",
        "\n",
        "            # Barra de progreso basada en segmentos\n",
        "            num_segments = len(transcription.get(\"segments\", []))\n",
        "            for i, _ in enumerate(transcription.get(\"segments\", []), start=1):\n",
        "                progress_percentage = int((i / num_segments) * 100)\n",
        "                progress_bar.update(progress_percentage - progress_bar.n)\n",
        "\n",
        "    # Guardar la transcripción en un archivo de texto\n",
        "    transcript_path = os.path.join(output_folder, f\"{base_name}_transcription.txt\")\n",
        "    with open(transcript_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(transcription[\"text\"])\n",
        "\n",
        "    print(\"Transcripción completada.\")\n",
        "    print(f\"Transcripción guardada en: {transcript_path}\")\n",
        "\n",
        "    # Descargar automáticamente el archivo de transcripción\n",
        "    files.download(transcript_path)\n",
        "\n",
        "# Widgets para control de flujo\n",
        "def create_transcription_interface():\n",
        "    try:\n",
        "        setup_environment()\n",
        "        model = load_whisper_model_with_progress()\n",
        "        audio_file, output_folder, base_name = upload_audio_file()\n",
        "\n",
        "        language_dropdown = widgets.Dropdown(\n",
        "            options=[(name, code) for code, name in LANGUAGE_MAP.items()],\n",
        "            value='es',\n",
        "            description='Selecciona el idioma:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "        transcribe_button = widgets.Button(description=\"Iniciar Transcripción\")\n",
        "\n",
        "        def on_transcribe_button_clicked(_):\n",
        "            transcribe_audio_with_progress(model, audio_file, output_folder, base_name, language=language_dropdown.value)\n",
        "\n",
        "        transcribe_button.on_click(on_transcribe_button_clicked)\n",
        "\n",
        "        display(language_dropdown, transcribe_button)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Llamada a la interfaz\n",
        "create_transcription_interface()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyODQarm9bqgzoCPCmBdT3pP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}